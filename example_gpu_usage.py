# -*- coding: utf-8 -*-
"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤ PyTorch
"""

import torch
import torch.nn as nn
from src.gpu_config import (
    configure_gpu, 
    get_device, 
    print_device_info,
    print_memory_usage,
    clear_gpu_memory,
    set_seed
)


def main():
    """
    –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –≤ PyTorch
    """
    
    # 1. –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ
    print("=" * 70)
    print("–ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø GPU –í PYTORCH")
    print("=" * 70)
    
    print_device_info()
    
    # 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ GPU —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
    device = configure_gpu(
        device_id=0,           # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–≤—ã–π GPU
        memory_fraction=None,  # –ë–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ (–∏–ª–∏ 0.8 –¥–ª—è 80%)
        allow_tf32=True        # –í–∫–ª—é—á–∏—Ç—å TensorFloat-32 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    )
    
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–µ–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    # device = get_device(prefer_gpu=True)
    
    # 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    set_seed(42)
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏
    print("\n" + "=" * 70)
    print("–°–û–ó–î–ê–ù–ò–ï –ò –ü–ï–†–ï–ù–û–° –ú–û–î–ï–õ–ò –ù–ê GPU")
    print("=" * 70)
    
    class SimpleModel(nn.Module):
        def __init__(self):
            super(SimpleModel, self).__init__()
            self.fc1 = nn.Linear(512, 256)
            self.fc2 = nn.Linear(256, 128)
            self.fc3 = nn.Linear(128, 10)
            self.relu = nn.ReLU()
        
        def forward(self, x):
            x = self.relu(self.fc1(x))
            x = self.relu(self.fc2(x))
            x = self.fc3(x)
            return x
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –∏ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ GPU
    model = SimpleModel().to(device)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ –∏ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –Ω–∞ {device}")
    print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in model.parameters()):,}")
    
    # 5. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ GPU
    print("\n" + "=" * 70)
    print("–†–ê–ë–û–¢–ê –° –î–ê–ù–ù–´–ú–ò –ù–ê GPU")
    print("=" * 70)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ–Ω–∑–æ—Ä—ã –Ω–∞ GPU
    batch_size = 32
    input_data = torch.randn(batch_size, 512).to(device)
    print(f"‚úÖ –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω—ã –Ω–∞ {device}")
    print(f"   –†–∞–∑–º–µ—Ä: {input_data.shape}")
    print(f"   –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {input_data.dtype}")
    
    # 6. –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
    with torch.no_grad():
        output = model(input_data)
    
    print(f"‚úÖ –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω –Ω–∞ GPU")
    print(f"   –í—ã—Ö–æ–¥ —Ä–∞–∑–º–µ—Ä: {output.shape}")
    
    # 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
    print_memory_usage(device_id=0)
    
    # 8. –ü—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–∏—è (–Ω–µ—Å–∫–æ–ª—å–∫–æ –∏—Ç–µ—Ä–∞—Ü–∏–π)
    print("=" * 70)
    print("–ü–†–ò–ú–ï–† –û–ë–£–ß–ï–ù–ò–Ø –ù–ê GPU")
    print("=" * 70)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–∫–∏
    labels = torch.randint(0, 10, (batch_size,)).to(device)
    
    # –ù–µ—Å–∫–æ–ª—å–∫–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –æ–±—É—á–µ–Ω–∏—è
    model.train()
    for epoch in range(5):
        optimizer.zero_grad()
        
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
        outputs = model(input_data)
        loss = criterion(outputs, labels)
        
        # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥
        loss.backward()
        optimizer.step()
        
        print(f"–≠–ø–æ—Ö–∞ {epoch + 1}/5, Loss: {loss.item():.4f}")
    
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    
    # 9. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
    print_memory_usage(device_id=0)
    
    # 10. –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
    del model, input_data, output, labels
    clear_gpu_memory()
    
    print("\n" + "=" * 70)
    print("–ü–†–ò–ú–ï–† –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
    print("=" * 70)
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–æ–≤–µ—Ç—ã
    print("\nüí° –°–û–í–ï–¢–´ –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ GPU:")
    print("   1. –í—Å–µ–≥–¥–∞ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç–µ –º–æ–¥–µ–ª—å –∏ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–¥–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: .to(device)")
    print("   2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ torch.cuda.empty_cache() –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏")
    print("   3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ with torch.no_grad() –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞")
    print("   4. –í–∫–ª—é—á–∏—Ç–µ torch.backends.cudnn.benchmark = True –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
    print("   5. –î–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ gradient accumulation")
    print("   6. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ GPU")
    

if __name__ == "__main__":
    main()
